# -*- coding: utf-8 -*-
"""TotalPower.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mAcEPXzSycQGwpsGnecI3X67uTs_0DJx
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
print("Done!")

url = '/content/sample_data/dataset - dataset.csv'
data = pd.read_csv(url)
data.head()

data.shape

data = data.sort_values(by="time", ascending=True)  #data is sorted as per the time in ascending order
data

time = data['time'].nunique()
ref = data['reflectivity'].nunique()
power = data['power'].nunique()
vel = data['velocity'].nunique()
width = data['spectrum_width'].nunique()

print('Time : ' , time )
print('Reflectivity : ' , ref )
print('Power : ' , power )
print('Velocity : ' , vel )
print('Spectrum Width : ' , width)

duplicateRows = data[data.duplicated(["time"])]
print(duplicateRows)

data = data.drop_duplicates(subset=['time'])
data = data.drop(['name'] , axis=1)
data.head()

data = data.set_index(["time"])
data.head()

sns.pairplot(data)

import pandas as pd
from sklearn.model_selection import train_test_split


# Split the dataset into features (X) and target (y)
X = data.drop('power', axis=1)  # Replace 'target_variable' with the name of your target variable column
y = data['power']

y = pd.DataFrame(y)  #convert the datastructure of 'y' into dataframes
y

from sklearn.preprocessing import MinMaxScaler

# scale feature dataset
scaler = MinMaxScaler()
transformed_x = scaler.fit_transform(X)
transformed_x = pd.DataFrame(X)
print(transformed_x)

scaler = MinMaxScaler()
transformed_y = scaler.fit_transform(y)
transformed_y = pd.DataFrame(y)
print(transformed_y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print(X_train.shape,y_train.shape,X_test.shape)

X_train = np.expand_dims(X_train, axis = 2)

X_test = np.expand_dims(X_test,axis = 2)

X_test

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

from keras.models import Sequential
from keras.layers import LSTM, Dense

# Define the model architecture
model = Sequential()
# model.add(LSTM(72, input_shape=(3,1)))
model.add(LSTM(90, activation='relu', input_shape=(3, 1)))
model.add(Dense(16, activation='relu'))
model.add(Dense(1,activation='linear'))
model.add(Dense(1))

# Print a summary of the model architecture
model.summary()

model.compile(loss='MeanSquaredError', optimizer=Adam(learning_rate=0.001), metrics=['RootMeanSquaredError'])



history = model.fit(X_train, y_train, epochs=150, steps_per_epoch=10, batch_size=20, shuffle=False)

# Save the entire model to a file
model.save('lstm_model.h5')

from tensorflow.keras.models import load_model
model=load_model('lstm_model.h5')

values = model.predict(X_test)

loss, rmse = model.evaluate(X_test, y_test)
print("Test loss:", loss)
print("Test RMSE:", rmse)

predictions = pd.DataFrame(y_test)
predictions["pow_pred"] = values
#predictions["pow_pred"] = predictions["pow_pred"].astype(int)
predictions.sort_index(axis=0, kind='mergesort')
predictions.head()

import matplotlib.pyplot as plt

# Set the figure size to a reasonable value
plt.figure(figsize=(8, 6))

# Add a title to the plot and set font size
plt.title("power (Actual vs. Prediction)", fontsize=16)

# Plot the actual reflectivity data and label the line
plt.plot(predictions['power'], label='Actual power')

# Plot the predicted reflectivity data and label the line
plt.plot(predictions['pow_pred'], label='Predicted power')

# Add a legend to the plot
plt.legend()

# Label the x and y axes and set font size
plt.xlabel('Index', fontsize=12)
plt.ylabel('power', fontsize=12)

# Set the tick label size
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

# Show the plot
plt.show()